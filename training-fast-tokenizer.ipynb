{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:39:55.065169Z",
     "end_time": "2023-06-03T15:40:02.376610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datasets import load_from_disk\n",
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer, DistilBertTokenizerFast\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('test-tokenizer-cleaned-30000')\n",
    "# tokenized_datasets = load_from_disk('distilbert-model/tokenized-dataset')\n",
    "lm_datasets = load_from_disk('distilbert-model/lm_dataset-30000')\n",
    "dataset = load_from_disk(\"cleaned-data-mc4-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from tokenizers.trainers import BpeTrainer, WordPieceTrainer\n",
    "# trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T15:46:48.178258Z",
     "end_time": "2023-05-30T15:46:48.189264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from tokenizers.pre_tokenizers import Whitespace\n",
    "# tokenizer.pre_tokenizer = Whitespace()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T12:17:42.797402Z",
     "end_time": "2023-05-29T12:17:42.813885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\Davit6174\\PycharmProjects\\huggingface\\web-crawl-mc4\\train\\cache-1808b37876d061fd.arrow and C:\\Users\\Davit6174\\PycharmProjects\\huggingface\\web-crawl-mc4\\train\\cache-2d9403e9c6be26c7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 1000\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_size = 10000\n",
    "# test_size = int(0.1 * train_size)\n",
    "#\n",
    "# downsampled_dataset = dataset[\"train\"].train_test_split(\n",
    "#     train_size=train_size, test_size=test_size, seed=42\n",
    "# )\n",
    "# downsampled_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T13:32:39.531847Z",
     "end_time": "2023-05-29T13:32:39.662066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'files': 'DatasetDict' object cannot be converted to 'Sequence'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m special_tokens \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[UNK]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[PAD]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[CLS]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[SEP]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[MASK]\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      7\u001B[0m trainer \u001B[38;5;241m=\u001B[39m trainers\u001B[38;5;241m.\u001B[39mWordPieceTrainer(min_frequency\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, special_tokens\u001B[38;5;241m=\u001B[39mspecial_tokens)\n\u001B[1;32m----> 8\u001B[0m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdownsampled_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspecial_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspecial_tokens\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\huggingface\\venv\\lib\\site-packages\\tokenizers\\implementations\\byte_level_bpe.py:98\u001B[0m, in \u001B[0;36mByteLevelBPETokenizer.train\u001B[1;34m(self, files, vocab_size, min_frequency, show_progress, special_tokens)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(files, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m     97\u001B[0m     files \u001B[38;5;241m=\u001B[39m [files]\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: argument 'files': 'DatasetDict' object cannot be converted to 'Sequence'"
     ]
    }
   ],
   "source": [
    "# from tokenizers import trainers\n",
    "# def batch_iterator(batch_size=100):\n",
    "#     for i in range(0, len(downsampled_dataset), batch_size):\n",
    "#         yield dataset[i : i + batch_size][\"text\"]\n",
    "#\n",
    "# special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "# trainer = trainers.WordPieceTrainer(min_frequency=3, special_tokens=special_tokens)\n",
    "# tokenizer.train_new_from_iterator(downsampled_dataset, vocab_size=30000, min_frequency=3, special_tokens=special_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T13:14:57.239054Z",
     "end_time": "2023-05-29T13:14:57.246490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '__getstate__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DistilBertTokenizerFast\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Pass the vocabulary and merges to DistilBertTokenizerFast\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m distilbert_tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mDistilBertTokenizerFast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer_object\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\huggingface\\venv\\lib\\site-packages\\transformers\\models\\distilbert\\tokenization_distilbert_fast.py:159\u001B[0m, in \u001B[0;36mDistilBertTokenizerFast.__init__\u001B[1;34m(self, vocab_file, tokenizer_file, do_lower_case, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    133\u001B[0m     vocab_file\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    144\u001B[0m ):\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    146\u001B[0m         vocab_file,\n\u001B[0;32m    147\u001B[0m         tokenizer_file\u001B[38;5;241m=\u001B[39mtokenizer_file,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    157\u001B[0m     )\n\u001B[1;32m--> 159\u001B[0m     normalizer_state \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getstate__\u001B[49m())\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    161\u001B[0m         normalizer_state\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlowercase\u001B[39m\u001B[38;5;124m\"\u001B[39m, do_lower_case) \u001B[38;5;241m!=\u001B[39m do_lower_case\n\u001B[0;32m    162\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m normalizer_state\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrip_accents\u001B[39m\u001B[38;5;124m\"\u001B[39m, strip_accents) \u001B[38;5;241m!=\u001B[39m strip_accents\n\u001B[0;32m    163\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m normalizer_state\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandle_chinese_chars\u001B[39m\u001B[38;5;124m\"\u001B[39m, tokenize_chinese_chars) \u001B[38;5;241m!=\u001B[39m tokenize_chinese_chars\n\u001B[0;32m    164\u001B[0m     ):\n\u001B[0;32m    165\u001B[0m         normalizer_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(normalizers, normalizer_state\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute '__getstate__'"
     ]
    }
   ],
   "source": [
    "# from transformers import DistilBertTokenizerFast\n",
    "#\n",
    "# # Pass the vocabulary and merges to DistilBertTokenizerFast\n",
    "# distilbert_tokenizer = DistilBertTokenizerFast(tokenizer_object=tokenizer)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "\n",
    "def get_training_corpus():\n",
    "    data = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]])\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = data[start_idx : start_idx + 1000]\n",
    "        yield samples[\"text\"]\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:05:47.145089Z",
     "end_time": "2023-06-03T02:05:47.152091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:05:48.408508Z",
     "end_time": "2023-06-03T02:05:48.424509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "('test-tokenizer-cleaned-30000\\\\tokenizer_config.json',\n 'test-tokenizer-cleaned-30000\\\\special_tokens_map.json',\n 'test-tokenizer-cleaned-30000\\\\vocab.txt',\n 'test-tokenizer-cleaned-30000\\\\added_tokens.json',\n 'test-tokenizer-cleaned-30000\\\\tokenizer.json')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer = tokenizer.train_new_from_iterator(training_corpus, 30000)\n",
    "new_tokenizer.save_pretrained(\"test-tokenizer-cleaned-30000\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:05:49.777554Z",
     "end_time": "2023-06-03T02:05:51.772495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('test-tokenizer-cleaned-30000')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T08:26:45.433601Z",
     "end_time": "2023-06-03T08:26:45.459208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# tokenizer = test_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:07:53.570262Z",
     "end_time": "2023-06-03T02:07:53.582273Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T08:24:28.329169Z",
     "end_time": "2023-06-03T08:24:28.338166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1836440 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0506a136992e409b9318082679431c3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/459111 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15397daef917449d97b9f082b43e9ff4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2279 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f85d239149944b7af14e561805be817"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/34 shards):   0%|          | 0/1836440 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "878f06e6b5bf46dca1a06689a6d9d126"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/9 shards):   0%|          | 0/459111 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc0a3df982ab4274995be618f275e278"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/2279 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d94947556cb4927915d6c066bf48aed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids'],\n        num_rows: 1836440\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids'],\n        num_rows: 459111\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids'],\n        num_rows: 2279\n    })\n})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_datasets.save_to_disk('distilbert-model/tokenized-dataset-30000')\n",
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T08:29:25.223110Z",
     "end_time": "2023-06-03T09:29:26.417668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:42:26.248486Z",
     "end_time": "2023-06-03T02:42:26.274534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "chunk_size = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:39:14.358140Z",
     "end_time": "2023-06-03T15:39:14.378115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 551'\n",
      "'>>> Review 1 length: 17'\n",
      "'>>> Review 2 length: 304'\n"
     ]
    }
   ],
   "source": [
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:42:31.166955Z",
     "end_time": "2023-06-03T02:42:31.174459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 872'\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:42:33.286506Z",
     "end_time": "2023-06-03T02:42:33.290506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 360'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T02:42:35.431380Z",
     "end_time": "2023-06-03T02:42:35.439945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    chunk_size = 512\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T09:29:26.433824Z",
     "end_time": "2023-06-03T09:29:26.469735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=16):   0%|          | 0/1836440 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f9912ad6dde4e8d94743c27e1c67032"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map (num_proc=16):   0%|          | 0/459111 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c657d7127d247b7a86e97608e2b2b37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map (num_proc=16):   0%|          | 0/2279 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb2199e0a4a64208919fd604e0718744"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/55 shards):   0%|          | 0/2509639 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de62cbaedf7e4426bbe1453cbdf58415"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/14 shards):   0%|          | 0/626095 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e447d14c53a4c65b5d649b9cc58a1e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/3075 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b8f84b1fbd74665b10aea1853e89ede"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 2509639\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 626095\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 3075\n    })\n})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True, num_proc=16)\n",
    "lm_datasets.save_to_disk('distilbert-model/lm_dataset-30000')\n",
    "lm_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T09:29:26.449377Z",
     "end_time": "2023-06-03T10:14:32.952996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "'შემთხვევა [SEP] [CLS] საქართველოს მთავრობისა და სპორტისა და ახალგაზრდობის საქმეთა სამინისტროს სტრატეგიისა და პრიორიტეტული მიმართულებების, ასევე საქართველოს ახალგაზრდული პოლიტიკის გათვალისწინებით, მიმდინარე წელს სსიპ „ ბავშვთა და ახალგაზრდობის განვითარების ფონდის “ პროგრამულ პრიორიტეტებად შემდეგი მიმართულებები განისაზღვრა : ა ) დასაქმების ხელშეწყობა და არაფორმალური განათლება : ა. ა ) სოციალური მეწარმეობის ხელშეწყობა ( შენიშვნა : საქართველოს სამოქალაქო კოდექსის 25 - ე მუხლის მე - 5 პუნქტი – არასამეწარმეო ( არაკომერციული ) იურიდიული პირი უფლებამოსილია ეწეოდეს დამხმარე ხასიათის სამეწარმეო საქმიანობას, რომლიდან მიღებული მოგებაც უნდა მოხმარდეს არასამეწარმეო ( არაკომერციული ) იურიდიული პირის მიზნების რეალიზებას. ასეთი საქმიანობის შედეგად მიღებული მოგების განაწილება არასამეწარმეო ( არაკომერციული ) იურიდიული პირის დამფუძნებლებს, წევრებს, შემომწირველებს, აგრეთვე ხელმძღვანელობისა და წამომადგენლობითი უფლებამოსილების მქონე პირებს შორის დაუშვებელია. პრიორიტეტი სოციალური მეწარმეობა ნიშნავს კანონმდებლობით გათვალისწინებულ დამხმარე ხასიათის სამეწარმეო საქმიანობას, რომელსაც გააჩნია სოციალური მისია და არ ემსახურება ბიზნეს - ინტერესებს, სოციალური მეწარმეობის მთავარი მიზანი ფოკუსირებულია საზოგადოების კეთილდღეობაზე და მიღებული მოგების სოციალური მიზნებისთვის მიმართვაზე ; ა. ბ ) სკოლიდან სამუშაოზე გადასვლის პროცესის ხელშეწყობა ; ბ ) ცხოვრების ჯანსაღი წესი და მასობრივი სპორტი : ბ. ა ) მასობრივი სპორტის განივთარების ხელშეწყობა ; ბ. ბ ) ჯანსაღი ცხოვრების წესის პოპულარიზაცია ; გ ) სამოქალაქო მონაწილეობის გაზრდის ხელშეწყობა : გ. ა ) გარემოს დაცვა ; გ. ბ ) გადაწყვეტილების მიღებაში ჩართვა ; გ. გ ) კულტურა ; დ ) ინოვაციებისა და ტექნოლოგიური გამოგონებების ხელშეწყობა ( ახალგაზრდებში ინოვაციებისა და სტარტ - აპ ტექნოლოგიური გამოგონებების მხარდაჭერის პრიორიტეტი ) ა ) პროექტებს მაღალმთიანი რეგიონებისა და კომპაქტური დასახლებების შესახებ ; ბ ) პროექტებს ეთნიკურ უმცირესობათა წარმომადგენელი და სახელმწიფო ახალგაზრდული პოლიტიკის დოკუმენტის ( თავი მე - 3, პუნქტი მე - 3 ) მიხედვით განსაზღვრული სპეციალური საჭიროებების მქონე ახალგაზრდების საზოგადოებრივ ცხოვრებაში ინტეგრაციის თაობაზე. საკონკურსო პროცედურებისა თუ პრიორიტეტების შესახებ მეტი ინფორმაციის მისაღებად ჩამოტვირთეთ და გაეცანით კონკურსის გზამკვლევს. [SEP] [CLS] არქეოლოგმა, უძველესი ფილოსოფოსმა ვანგ ენთიანმა დაურეკა დათარიღებული პროექტი – kcchip ტექნიკა დღიურში არქეოლოგები, უძველესი ფილოლოგიის ექსპერტები, წინასწარი ქინის ისტორიის მეცნიერ ექსპერტები, შანდონგის მუზეუმის კვლევითი ბიბლიოთეკარი ვანგ ენთი მუზეუმი ბატონი wang entian გარდაიცვალა 28 აგვისტოს, 2017 წელს ჯინანში, წლის ასაკში 86. wang entian ხელმძღვანელობდა linzi qi gucheng ქალაქის საბურღი, პირველი აღმოჩენა qi qi მონეტა ფულის ნანგრევები და თავმჯდომარეობდა yidu ( ახლა qingzhou ქალაქი subu tun shang dynasty სასაფლაოზე გათხრები აღმოაჩინა, რომ ყველაზე დიდი გარეთ anyang yindu, უმაღლესი სპეციფიკაციები, დაკრძალვის ბრინჯაოს ყველაზე მნიშვნელოვანი, მკვლელობის ყველაზე მეტი მოწამის გვიან საფლავი wang entian ჰქონდა ეჭვქვეშ “ გაცნობის პროექტი ”, რომ დათარიღებული არქეოლოგიური აღმოჩენები და კვლევებიდან 10 წელი გამოქვეყნდა პროექტი “ მარტივი ”, რომ დასავლური ჟოუ “ ქრონოლოგია ” წლების განმავლობაში უწევდა კორექტი'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1234][\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T01:25:02.410637Z",
     "end_time": "2023-06-04T01:25:02.434743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'ხადიჯა ისმაილოვას პირადი ცხოვრების ამსახველი უკანონო ჩანაწერები. თუმცა გამომძიებელი ჟურნალისტი არ აპირებს ფარ - ხმლის დაყრას და აცხადებს, რომ მოვლენათა ნებისმიერი განვითარების შემთხვევაში არ აპირებს საზღვარგარეთ დარჩენას. „ მისი დაპატიმრება იქნება უძლიერესი დარტყმა ხელისუფლების ზეწოლის ქვეშ მყოფ აზერბაიჯანულ მედიასა და სამოქალაქო სექტორზე “, - ამბობს რებეკა ვინსენტი, აშშ - ის ყოფილი დიპლომატი და ამჟამად უფლებადამცველი აქტივისტი. ხადიჯა ისმაილოვა, რომელიც სტრასბურგში იმყოფებოდა მივლინებით, 3 ოქტომბერს ბრუნდება ბაქოში. ამავე თემაზე [SEP] [CLS] ჟანა ტარხანოვა, ვლადიკავკაზი - ცხინვალი [SEP] [CLS] პაატა ბურჭულაძე : “ ვაი, ჩემო საქართველო ” • artinfo. ge ოპერის მომღერალი პაატა ბურჭულაძე ქვეყანაში მიმდინარე მოვლენებს აფასებს : “ როგორც იქნა, გამოირთო “ რუსთავი 2 ” და ხომ ატყობთ რა საამო სიმშვიდეა ქვეყანაში. აღარავინ ტეხს განგაშს, რომ კორუფციაა და სიღარიბე, აღარც ოკუპაციის თემა მუსირებს. აგერ, ია კერძაიას სიცოცხლის მოსპობაში ბრალეული მხარე ვერ იქნა აღმოჩენილი და საქმე დახურეს. სამაგიეროდ, მამუკა ხაზარაძეს პასუხს აგებინებენ მამუკა ხაზარაძისვე დაზარალებაში, სხვა დაზარალებული ან მომჩივანი ვერ იპოვნეს. უსახლკაროდ მიტოვებული ოჯახებისთვის ფონდ “ იავნანას ” მიერ ნაჩუქარ სახლებს რემონტი დაუწუნეს და ორი წელია მათ პურის ფულითაც კი აღარავინ დახმარებია. პროკურატურამ ეძება ფონდში და მხოლოდ დახმარებული და სარგებელმიღებული ხალხი აღმოაჩინა, მაგრამ მავნებლურად საქმეს მაინც არ ხურავენ, ბოლომდე უნდათ “ იავნანა ” მოსპონ … და ალბათ, რა მშვენიერი იქნებოდა ივანიშვილისთვის ასწლოვანი ხეების შრიალში დღეების გატარება ინგა გრიგოლია და ტვ პირველიც რომ არ დაურღვევდნენ მყუდროებას ახალი სატელევიზიო სეზონიდან. ისე ძალიან უნდა მას აგვისტოში გააჩუმოს და მოათავოს ყველაფერი, რომ მისი მონები ბატონის სურვილების შესასრულებლად ყველაფერზე ხელს აწერენ, ყველა საქციელზე მზად არიან და შემდეგ უტიფარ გამართლებასაც მარტივად კადრულობენ. რაც მთავარია, სიჩუმეა … სიჩუმეა და აღარავინ წუხდება. ვაი, ჩემო საქართველო … ” ნოდარ დუმბაძე სრულიად სამართლიანად არის … ამბავი, რომელიც გურამ რჩეულიშვილის სამართლიანობაში დაგარწმუნებთ გურამ რჩეულიშვილის შესახებ მისი შემოქმედების … გადავა თუ არა “ კომედი ჯგუფი ” ნიკა გვარამიას არხზე? მარიამ ხაჭვანის განცხადება : “ იცოდეთ სიმართლე! ” [SEP] [CLS] გრძნობები @ grdznobebi - ქართული / esperanto ქართული » esperanto გრძნობები სურვილი emi emi ჩვენ გვაქვს სურვილი. ni e - - -. ni emas. ჩვენ არ გვაქვს სურვილი. ni n - e - - -. ni ne emas. შიში ti - i timi მეშინია. mi t - -'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:40:15.208118Z",
     "end_time": "2023-06-03T15:40:15.226202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, DataCollatorForWholeWordMask\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "wholde_word_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer, mlm_probability=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:40:21.146256Z",
     "end_time": "2023-06-03T15:40:21.150256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] ხადიჯა ისმაილოვა : ხუც მათ დღის სინათლეზე გამოვიყვან მედია [MASK] ისმაილოვა : მე მათ დღის სინათლეზე გამოვიყვან ოქტომბერი 03, [MASK] აზერბაიჯანელი გამომძიებელი ჟურნალისტი ხადიჯა [MASK] ამბობს, რომ მას, სამშობლოში [MASK] შემთხვევაში, დაპატიმრება ემუქრება. ისმაილოვას [MASK] განცხადების ფონი [MASK] ზნე [MASK] მდიდარ აზერბაიჯანში დამოუკიდებელი ჟურნალისტებისა და უფლებადამცველი [MASK] [MASK] დევნა, რასაც საერთაშორისო საზოგადოების [MASK] არაერთი სპროტესტო განცხადება [MASK] [MASK] ხადიჯა ისმაილოვა, რომელიც [MASK] თავისუფლების აზერბაიჯანულ სამსახურში დილის პროგრამას უძღვება [MASK] პრეზიდენტ ილ [MASK] [MASK] [MASK] [MASK] და [MASK] ოჯახისmav ბიზნესინტერესების შესახებ [MASK] [MASK] მწვავე პუბლიკაციით არის ცნობილი. როგორც ხადიჯა ამბობს, მის წინააღმდეგ vax მუხლით აღძრულია სისხლის სამართლის საქმე და 3 ოქტომბერს სასამართლოშია გამოძახებული : „ გაფრთხილებული ვარ, [MASK] მივლინებიდან დაბრუნების შემდეგ დამაპატიმრებენ, რაც დაშინების [MASK] მეთოდია. დარწმუნებული ვარ, მათ სურთ ან არ დავბრუნდე აზერბაიჯანში, ანდა შევშინდე [MASK] აღარ [MASK] [MASK] ხმამაღლა იმაზე, რაც აზერბაიჯანში ხდება. მათ უნდა შეიგნონ, რომ ამ მეთოდით ჩემთან ვერაფერს გახდებიან [MASK]. ხადიჯა ისმაილოვა [MASK] წინააღმდეგ [MASK] უმწ გამოძიებას აზერბაიჯანში ჟურნალისტებისა და აქტივისტების იმ დევნის [MASK] [MASK] ნაწილად მიიჩნევს, რაც ბაქოში გაძლიერდა სწორედ [MASK] შემდეგ, [MASK] მაისში აზერბაიჯანი ევროსაბჭოს მინისტრთა საბჭოს მორიგე [MASK] გახდა. ადგილობრივი უფლებადამცველი ორგანიზაციების [MASK], აზერბაიჯანში დაახლოებით 87 პოლიტიკური პატიმარია, მათ შორის 14 დამოუკიდებელი ჟურნალისტი და [MASK] უწმინდ. ხადიჯა ისმაილოვას წანააღმდეგ [MASK] სამართლის საქმეა [MASK] ცილისწამების მუხლით. იგი ეფუძნება ისმაილოვას მიერ [MASK] [MASK] გამოქვეყნებულ ინფორმაციას იმის თაობაზე, რომ [MASK] სპეცსამსახურები ფარული გზით მოპოვებულ მაკ [MASK] [MASK] [MASK] [MASK] [MASK] მასალებს previous შანტაჟისათვის, რომ ერთმა ოპოზიციონერმა აქტივისტმა იჯაშუშოს და მეორეზე მიაწოდოს ინფორმაცია. ისმაილოვა აცხადებს, [MASK] მან, ერთ - ერთი ასეთი დაშანტაჟებული პირის თხოვნით, მისი ვინაობა არ ახსენა, მაგრამ მან მაინც უჩივლა ცილისწამების [MASK]. ხადიჯა ამბობს, რომ მისი განზრახვა [MASK] ამხილოს ის მეთოდი, რომლითაც ხელისუფლება მოქმედებს : „ აზერბაიჯანის ეროვნული უშიშროების სამინისტრო და აზერბაიჯანის სპეცსამსახურები ცნობილი არიან იმით, რომ საიდუმლოდ იწერენ [MASK] მიმართ კრიტიკულად განწყობილი ადამიანების სექსუალურ ცხოვრებას. ასეთი ჩანაწერები ჩემ წინააღმდეგაც გამოიყენეს, [MASK] სხვების წინააღმდეგაც. ჩემთვის ეს საქმე იქნება შესაძლებლობა, რომ მზის სინათლეზე გამოვიტანო აზერბაიჯანში დამკვირდებული ეს პრაქტიკა “. გასულ წელს ერთ - ერთმა ვებსაიტმა, რომელიც აზერბაიჯანის მმართველ „ [MASK] [MASK] აზერბაიჯანის პარტიასთან “ არის კავშირში, გამოაქვეყნა წერილი, სათაურით „ ხადიჯას სომეხი დედა [MASK] მოკვდეს “. სტატიაში [MASK] იყო ბაქოში მდებარე იმ დასახლების მისამართი, სადაც [MASK] [MASK] [MASK] ცხოვრობს. პუბლიკაციაში ასევე იყო ცნობა ხადიჯას დის შესახებ, [MASK] ვითომცდა თურქეთში „ სექსუალური ტრეფიკინგით “ [MASK] დაკავებული. [MASK] წელს კი ინტერნეტში გავრცელდა'\n",
      "\n",
      "'>>> [MASK] ისმაილოვას პირადი ცხოვრების ამსახველი უკანონო ჩანაწერები. თუმცა გამომძიებელი ჟურნალისტი არ აპირებს ფარ [MASK] ხმლის დაყრას და აცხადებს, რომ მოვლენათა ნებისმიერი [MASK] შემთხვევაში არ აპირებს საზღვარგარეთ დარჩენას [MASK] „ მისი დაპატიმრება იქნება უძლიერესი დარტყმა ხელისუფლების ზეწოლის ქვეშ მყოფ აზერბაიჯანულ მედიასა [MASK] [MASK] სექტორზე “, - ამბობს რებეკა ვინსენტი, აშშ - ის ყოფილი დიპლომატი და [MASK] უფლებადამცველი აქტივისტი. ხადიჯა ისმაილოვა, რომელიც სტრასბურგში იმყოფებოდა მივლინებით [MASK] 3 [MASK] ბრუნდება [MASK]. [MASK] თემაზე [SEP] [CLS] ჟანა ტარხანოვა,ნებო [MASK] [MASK] [MASK] [MASK] - ცხინ [MASK] [SEP] [CLS] პაატა ბურჭულაძე : “ ვაი, [MASK] საქართველო [MASK] • artinfo. ge ოპერის მომღერალი [MASK] ბურჭულაძე ქვეყანაში მიმდინარე [MASK] აფასებს : “ როგორც იქნა, გამოირთო “ რუსთავი 2 ” [MASK] ხომ ატყობთ რა საამო სიმშვიდეა ქვეყანაში. [MASK] ტეხს განგაშს, რომ კორუფციაა და სიღარიბე, აღარც ოკუპაციის თემა მუსირებს. აგერ [MASK] ია [MASK] საავადმყოფოების [MASK] სიცოცხლის მოსპობაში [MASK] [MASK] მხარე ვერ იქნა აღმოჩენილი და საქმე დახურეს. სამაგიეროდ, მამუკა ხაზარაძეს პასუხს აგებინებენ მამუკა ხაზარაძისვე დაზარალებაში, სხვა დაზარალებული ან მომჩივანი ვერ იპოვნეს. უსახლკაროდ მიტოვებული ოჯახებისთვის ფონდ [MASK] იავნანას ” მიერ ნაჩუქარ სახლებს რემონტი დაუწუნეს და ორი წელია მათ პურის ფულითაც კი [MASK] დახმარებია. პროკურატურამ ეძება [MASK] და მხოლოდ დახმარებული და სარგებელმიღებული ხალხი აღმოაჩინა [MASK] მაგრამ მავნებლურად საქმეს მაინც არ ხურავენ, ბოლომდე [MASK]ერძნ იავნანა ” მოსპონ … და ალბათ, რა მშვენიერი იქნებოდა ივანიშვილისთვის ასწლოვანი ხეების შრიალში [MASK] გატარება ინგა გრიგოლია და ტვ პირველი [MASK] რომ არ დაურღვევდნენ მყუდროებას ახალი სატელევიზიო სეზონიდან. ისე ძალიან [MASK] მას აგვისტოში გააჩუმოს და მოათავოს ყველაფერი [MASK] [MASK] მისი მონები ბატონის სურვილების შესასრულებლად [MASK] ხელს [MASK] [MASK], ყველა [MASK] [MASK] [MASK] არიან და შემდეგ უტიფარ [MASK] [MASK] [MASK] მარტივად კადრულობენ. რაც მთავარია, სიჩუმეა … სიჩუმეა და აღარავინ წუხდება. ვაი [MASK] ჩემო საქართველო … ” ნოდარ [MASK] [MASK] სრულიად სამართლიანად არის … [MASK], რომელიც [MASK] [MASK] ფშ სამართლიანობაში დაგარწმუნებთ გურამ რჩეულიშვილის შესახებ მისი შემოქმედების … გადავა თუ [MASK] “ კომედი ჯგუფი ” ნიკა გვარამიას არხზე? მარიამ ხაჭვანის განცხადება : “ იცოდეთ სიმართლე! ” [SEP] [CLS] გრძნობები @ grdznobebi - [MASK] / esperanto ქართული » esperanto გრძნობები [MASK] emi emi ჩვენ გვაქვს [MASK]. ni [MASK] - - -. [MASK] em [MASK]. ჩვენ არ გვაქვს სურვილი [MASK] ni n [MASK] e - - -. ni ne emas. შიში ti - i [MASK] [MASK] მეშინია. [MASK] t - [MASK]'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in wholde_word_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:41:14.063376Z",
     "end_time": "2023-06-03T15:41:14.086873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers.data.data_collator import tf_default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "        # სიტყვებსა და ტოკენებს შორის კავშირების დამყარება\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # სიტყვების შემთხვევითად შენიღბვა\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return tf_default_data_collator(features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:08:43.443107Z",
     "end_time": "2023-06-03T15:08:43.460519Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: [{'input_ids': [2, 16885, 19765, 30, 431, 562, 1419, 13774, 403, 5013, 1746, 6014, 16885, 19765, 30, 431, 562, 1419, 13774, 403, 5013, 1746, 3281, 1702, 16, 1598, 28060, 240, 1401, 23226, 7840, 16885, 19765, 2222, 16, 400, 595, 16, 8891, 8281, 1095, 16, 11950, 776, 9942, 18, 19765, 250, 421, 8496, 25388, 243, 7321, 692, 6819, 364, 14458, 5395, 16472, 243, 367, 24859, 240, 10563, 2074, 11640, 16, 2559, 1323, 3658, 2727, 6171, 840, 16914, 245, 1571, 7759, 18, 16885, 19765, 16, 620, 6491, 3627, 8840, 391, 7063, 15793, 15204, 18492, 382, 16, 2386, 5878, 10409, 3911, 1503, 243, 367, 666, 3491, 9426, 9090, 242, 652, 381, 386, 855, 9168, 3858, 5507, 11775, 2804, 543, 2090, 18, 659, 16885, 2222, 16, 661, 1534, 28698, 7627, 28434, 243, 2418, 3330, 1183, 367, 23, 9117, 9125, 243, 14999, 841, 393, 30, 185, 10616, 446, 1172, 16, 400, 22764, 1330, 633, 8281, 638, 2653, 7669, 14005, 16, 650, 29888, 386, 10904, 7055, 243, 18, 5728, 1172, 16, 562, 10811, 478, 389, 10131, 807, 14458, 16, 10079, 1802, 789, 807, 367, 1532, 16828, 245, 11783, 3532, 16, 650, 14458, 1575, 18, 562, 523, 2706, 3921, 242, 16, 400, 421, 12151, 7199, 6716, 20795, 183, 18, 16885, 19765, 661, 1534, 2230, 521, 10599, 14458, 16472, 243, 367, 10563, 2074, 479, 27112, 3616, 388, 17594, 6786, 16, 650, 16585, 4488, 385, 1476, 595, 638, 16, 650, 16043, 19307, 9397, 21819, 15170, 2715, 12601, 236, 4343, 2370, 18, 3242, 24859, 240, 6740, 6677, 16, 14458, 2402, 5165, 1758, 3664, 1486, 16, 562, 985, 898, 5395, 7840, 367, 7091, 1911, 18, 16885, 19765, 250, 1614, 547, 1179, 2418, 3330, 11002, 28434, 28698, 7627, 18, 997, 15671, 19765, 250, 891, 3900, 5963, 15407, 3554, 1490, 4200, 16, 400, 8575, 21754, 380, 13190, 3987, 4727, 521, 3651, 3381, 881, 999, 5338, 388, 11445, 419, 7274, 29500, 8512, 852, 16, 400, 4666, 4017, 3520, 4423, 10563, 10837, 11856, 639, 602, 396, 367, 23278, 28672, 1949, 18, 19765, 3635, 16, 400, 759, 16, 453, 17, 665, 1322, 3077, 1275, 1300, 446, 3850, 13044, 16, 666, 23895, 389, 10928, 243, 16, 612, 759, 1397, 13968, 1418, 28698, 456, 18, 16885, 2222, 16, 400, 666, 4791, 412, 543, 421, 810, 396, 444, 7055, 16, 6697, 4156, 5382, 30, 185, 8575, 1491, 9225, 2679, 367, 8575, 21754, 380, 2090, 1440, 8002, 16, 400, 4521, 252, 7126, 20420, 562, 862, 21587, 19405, 4618, 14415, 6586, 18, 1322, 14520, 609, 1534, 392, 16387, 16, 16387, 9366, 1534, 392, 18, 3270, 465, 1183, 967, 4562, 16, 400, 3189, 13774, 403, 5013, 1737, 245, 14458, 658, 10849, 7527, 465, 13589, 183, 18, 6581, 920, 453, 17, 4666, 20126, 462, 401, 16, 620, 8575, 5531, 185, 144, 860, 8575, 12148, 464, 183, 543, 9882, 16, 11232, 5257, 16, 27347, 185, 16885, 250, 15374, 240, 1795, 523, 19026, 752, 183, 18, 6454, 9530, 583, 16585, 2406, 479, 23771, 363, 12281, 16, 1274, 16885, 250, 1795, 7793, 18, 28319, 912, 583, 14838, 16885, 250, 2375, 855, 16, 620, 6754, 15908, 10229, 185, 5972, 18184, 4138, 259, 183, 543, 8304, 18, 1459, 920, 571, 11089, 9794], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 17, 18, 19, 20, 21, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 36, 37, 38, 38, 39, 40, 41, 41, 42, 42, 43, 43, 44, 45, 46, 46, 47, 48, 48, 49, 49, 50, 51, 52, 53, 54, 55, 56, 57, 57, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 67, 68, 69, 70, 71, 71, 72, 73, 74, 74, 75, 75, 75, 76, 77, 78, 79, 80, 80, 80, 80, 80, 81, 82, 83, 84, 85, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 97, 98, 99, 100, 101, 102, 103, 104, 104, 105, 105, 105, 106, 107, 108, 108, 109, 110, 111, 112, 112, 112, 113, 114, 115, 115, 115, 116, 117, 118, 118, 119, 120, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 129, 130, 131, 132, 133, 133, 133, 134, 135, 136, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 146, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 160, 161, 162, 163, 163, 164, 165, 165, 166, 167, 168, 168, 169, 170, 171, 172, 173, 174, 174, 175, 176, 177, 178, 179, 180, 181, 182, 182, 183, 184, 185, 185, 186, 187, 188, 189, 190, 190, 191, 192, 193, 194, 195, 196, 197, 198, 198, 199, 200, 201, 202, 203, 204, 205, 206, 206, 207, 208, 209, 209, 210, 210, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 231, 232, 233, 234, 234, 235, 235, 235, 235, 235, 235, 236, 236, 237, 238, 238, 238, 239, 240, 241, 242, 242, 242, 243, 243, 244, 244, 244, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 260, 260, 260, 261, 262, 263, 264, 265, 266, 267, 267, 268, 269, 270, 271, 272, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 281, 282, 283, 283, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 298, 299, 300, 301, 302, 303, 304, 304, 305, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 317, 318, 319, 320, 321, 322, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 332, 333, 333, 333, 334, 335, 335, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 345, 345, 346, 347, 348, 349, 350, 351, 351, 352, 353, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 363, 364, 364, 365, 366, 367, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 376, 377, 378, 379, 380, 380, 381, 382, 383, 384, 385, 386, 387, 388, 388, 389, 390, 391, 392, 393, 393, 394, 395, 396, 397, 397, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406], 'labels': [2, 16885, 19765, 30, 431, 562, 1419, 13774, 403, 5013, 1746, 6014, 16885, 19765, 30, 431, 562, 1419, 13774, 403, 5013, 1746, 3281, 1702, 16, 1598, 28060, 240, 1401, 23226, 7840, 16885, 19765, 2222, 16, 400, 595, 16, 8891, 8281, 1095, 16, 11950, 776, 9942, 18, 19765, 250, 421, 8496, 25388, 243, 7321, 692, 6819, 364, 14458, 5395, 16472, 243, 367, 24859, 240, 10563, 2074, 11640, 16, 2559, 1323, 3658, 2727, 6171, 840, 16914, 245, 1571, 7759, 18, 16885, 19765, 16, 620, 6491, 3627, 8840, 391, 7063, 15793, 15204, 18492, 382, 16, 2386, 5878, 10409, 3911, 1503, 243, 367, 666, 3491, 9426, 9090, 242, 652, 381, 386, 855, 9168, 3858, 5507, 11775, 2804, 543, 2090, 18, 659, 16885, 2222, 16, 661, 1534, 28698, 7627, 28434, 243, 2418, 3330, 1183, 367, 23, 9117, 9125, 243, 14999, 841, 393, 30, 185, 10616, 446, 1172, 16, 400, 22764, 1330, 633, 8281, 638, 2653, 7669, 14005, 16, 650, 29888, 386, 10904, 7055, 243, 18, 5728, 1172, 16, 562, 10811, 478, 389, 10131, 807, 14458, 16, 10079, 1802, 789, 807, 367, 1532, 16828, 245, 11783, 3532, 16, 650, 14458, 1575, 18, 562, 523, 2706, 3921, 242, 16, 400, 421, 12151, 7199, 6716, 20795, 183, 18, 16885, 19765, 661, 1534, 2230, 521, 10599, 14458, 16472, 243, 367, 10563, 2074, 479, 27112, 3616, 388, 17594, 6786, 16, 650, 16585, 4488, 385, 1476, 595, 638, 16, 650, 16043, 19307, 9397, 21819, 15170, 2715, 12601, 236, 4343, 2370, 18, 3242, 24859, 240, 6740, 6677, 16, 14458, 2402, 5165, 1758, 3664, 1486, 16, 562, 985, 898, 5395, 7840, 367, 7091, 1911, 18, 16885, 19765, 250, 1614, 547, 1179, 2418, 3330, 11002, 28434, 28698, 7627, 18, 997, 15671, 19765, 250, 891, 3900, 5963, 15407, 3554, 1490, 4200, 16, 400, 8575, 21754, 380, 13190, 3987, 4727, 521, 3651, 3381, 881, 999, 5338, 388, 11445, 419, 7274, 29500, 8512, 852, 16, 400, 4666, 4017, 3520, 4423, 10563, 10837, 11856, 639, 602, 396, 367, 23278, 28672, 1949, 18, 19765, 3635, 16, 400, 759, 16, 453, 17, 665, 1322, 3077, 1275, 1300, 446, 3850, 13044, 16, 666, 23895, 389, 10928, 243, 16, 612, 759, 1397, 13968, 1418, 28698, 456, 18, 16885, 2222, 16, 400, 666, 4791, 412, 543, 421, 810, 396, 444, 7055, 16, 6697, 4156, 5382, 30, 185, 8575, 1491, 9225, 2679, 367, 8575, 21754, 380, 2090, 1440, 8002, 16, 400, 4521, 252, 7126, 20420, 562, 862, 21587, 19405, 4618, 14415, 6586, 18, 1322, 14520, 609, 1534, 392, 16387, 16, 16387, 9366, 1534, 392, 18, 3270, 465, 1183, 967, 4562, 16, 400, 3189, 13774, 403, 5013, 1737, 245, 14458, 658, 10849, 7527, 465, 13589, 183, 18, 6581, 920, 453, 17, 4666, 20126, 462, 401, 16, 620, 8575, 5531, 185, 144, 860, 8575, 12148, 464, 183, 543, 9882, 16, 11232, 5257, 16, 27347, 185, 16885, 250, 15374, 240, 1795, 523, 19026, 752, 183, 18, 6454, 9530, 583, 16585, 2406, 479, 23771, 363, 12281, 16, 1274, 16885, 250, 1795, 7793, 18, 28319, 912, 583, 14838, 16885, 250, 2375, 855, 16, 620, 6754, 15908, 10229, 185, 5972, 18184, 4138, 259, 183, 543, 8304, 18, 1459, 920, 571, 11089, 9794]}, {'input_ids': [16885, 19765, 250, 3224, 2179, 13070, 8048, 14520, 18, 911, 1401, 23226, 7840, 389, 7281, 5886, 17, 2514, 427, 22667, 2274, 367, 3635, 16, 400, 19297, 2774, 1539, 1095, 389, 7281, 6793, 26843, 18, 185, 666, 11950, 776, 967, 20185, 1207, 608, 13028, 3492, 14305, 1793, 3304, 3075, 8840, 391, 19333, 243, 367, 3534, 1492, 22743, 183, 16, 17, 2222, 575, 12517, 243, 969, 1836, 398, 16, 1987, 17, 444, 2040, 10704, 367, 4762, 24859, 240, 10563, 398, 18, 16885, 19765, 16, 620, 22094, 8831, 22764, 6396, 16, 23, 9117, 27777, 16585, 18, 3179, 5845, 3, 2, 7510, 243, 4413, 235, 3512, 2596, 16, 6011, 1639, 246, 1776, 712, 17, 14202, 1051, 3, 2, 12284, 27751, 1214, 30, 183, 13553, 16, 6428, 1852, 184, 187, 3327, 508, 290, 230, 18, 767, 17695, 11795, 12284, 27751, 1214, 2182, 1514, 15364, 11770, 30, 183, 659, 3449, 16, 6158, 7529, 183, 5738, 22, 184, 367, 1523, 22333, 1813, 500, 29938, 245, 9934, 243, 2182, 18, 23392, 9990, 250, 9344, 639, 250, 16, 400, 14319, 23115, 367, 24101, 241, 236, 16, 11020, 18044, 2343, 2361, 6855, 18, 15185, 16, 6661, 1666, 8674, 250, 5055, 15075, 838, 2492, 932, 3785, 613, 3449, 10668, 367, 1183, 4000, 381, 18, 9226, 16, 6180, 23697, 250, 7033, 1315, 10042, 830, 6180, 27075, 369, 9450, 1056, 16, 707, 28126, 478, 527, 1850, 2363, 613, 28928, 18, 13187, 239, 14889, 418, 24361, 1435, 1099, 11031, 183, 6661, 4087, 2229, 184, 891, 11872, 689, 364, 22915, 24394, 1910, 265, 22869, 250, 367, 893, 4706, 562, 18470, 19349, 392, 571, 23392, 1857, 1730, 18, 18082, 2916, 382, 28259, 367, 773, 1857, 446, 367, 3019, 1313, 711, 25617, 2909, 14508, 16, 612, 10306, 241, 10394, 897, 4373, 1397, 389, 11318, 4712, 16, 4506, 12022, 183, 6661, 4087, 547, 184, 15075, 394, 188, 367, 1679, 16, 500, 9540, 3942, 7272, 501, 483, 16631, 29543, 13981, 4723, 16225, 14552, 27083, 27327, 367, 3314, 1107, 260, 400, 389, 1910, 14007, 29673, 19479, 541, 976, 12354, 5156, 633, 18, 894, 770, 523, 595, 15414, 3267, 22538, 250, 367, 411, 22785, 396, 1439, 16, 400, 666, 662, 380, 6514, 250, 1549, 10870, 16879, 11128, 2123, 7494, 20420, 16, 579, 7567, 2949, 2511, 1440, 367, 638, 29454, 8183, 4281, 2483, 392, 6904, 27564, 1588, 18, 650, 4802, 16, 21991, 243, 188, 21991, 243, 367, 23392, 17112, 515, 18, 13553, 16, 6428, 1852, 188, 184, 19899, 29321, 1214, 2663, 16690, 543, 188, 4241, 16, 620, 8808, 11064, 1163, 27823, 378, 1098, 20375, 829, 8808, 11064, 1163, 855, 666, 24041, 188, 13334, 467, 610, 183, 578, 1132, 4383, 184, 5533, 13817, 27837, 35, 6472, 14848, 2363, 250, 1571, 30, 183, 10130, 6492, 5, 184, 3, 2, 11117, 36, 3603, 11341, 22588, 1137, 17, 1451, 19, 2253, 5087, 27041, 1451, 87, 2253, 5087, 27041, 11117, 3560, 3761, 271, 3761, 271, 635, 2012, 3560, 18, 4353, 47, 17, 17, 17, 18, 4353, 3761, 572, 18, 635, 389, 2012, 3560, 18, 4353, 56, 17, 47, 17, 17, 17, 18, 4353, 4695, 3761, 572, 18, 7231, 16991, 17, 51, 2942, 271, 13320, 18, 6003, 62, 17, 17], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [407, 408, 408, 409, 410, 411, 412, 413, 414, 415, 416, 416, 417, 418, 419, 420, 421, 422, 422, 423, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 439, 440, 441, 441, 441, 442, 443, 444, 444, 445, 446, 447, 447, 448, 448, 449, 450, 451, 451, 452, 453, 454, 455, 456, 456, 456, 457, 457, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 466, 467, 467, 468, 469, 470, 471, 472, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, None, None, 0, 0, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 4, 5, 5, None, None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32, 33, 33, 34, 35, 35, 36, 36, 37, 38, 39, 40, 40, 41, 41, 41, 42, 43, 44, 44, 45, 46, 46, 46, 47, 48, 49, 50, 51, 51, 52, 53, 54, 55, 56, 56, 56, 57, 58, 58, 59, 59, 60, 61, 62, 63, 64, 65, 66, 66, 67, 68, 69, 70, 71, 71, 72, 73, 73, 73, 74, 75, 75, 76, 76, 77, 78, 79, 80, 81, 81, 81, 82, 83, 84, 85, 85, 85, 85, 86, 87, 87, 88, 89, 90, 90, 90, 91, 92, 93, 93, 93, 94, 95, 96, 96, 96, 96, 97, 98, 99, 100, 101, 102, 102, 103, 104, 105, 105, 106, 107, 108, 108, 109, 110, 111, 112, 112, 113, 114, 114, 114, 114, 115, 116, 117, 118, 119, 119, 119, 119, 120, 121, 122, 123, 123, 124, 125, 126, 127, 128, 128, 128, 129, 130, 130, 131, 132, 133, 134, 135, 136, 137, 138, 138, 139, 139, 140, 141, 141, 142, 143, 144, 145, 146, 147, 148, 148, 149, 150, 151, 151, 151, 152, 152, 153, 154, 155, 155, 156, 157, 158, 159, 160, 161, 162, 162, 162, 163, 164, 164, 164, 165, 166, 167, 168, 169, 169, 170, 170, 171, 171, 172, 173, 174, 175, 175, 176, 177, 178, 178, 179, 180, 181, 182, 183, 183, 184, 184, 184, 185, 186, 186, 187, 188, 189, 190, 191, 191, 192, 193, 193, 194, 195, 196, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 214, 215, 215, 216, 216, 216, 217, 218, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 227, 228, 229, 230, 231, 232, 233, 234, 235, 235, 235, 236, 237, 238, 239, 240, 241, 242, None, None, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 9, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 48, 49, 50, 51, 52, 53, 54], 'labels': [16885, 19765, 250, 3224, 2179, 13070, 8048, 14520, 18, 911, 1401, 23226, 7840, 389, 7281, 5886, 17, 2514, 427, 22667, 2274, 367, 3635, 16, 400, 19297, 2774, 1539, 1095, 389, 7281, 6793, 26843, 18, 185, 666, 11950, 776, 967, 20185, 1207, 608, 13028, 3492, 14305, 1793, 3304, 3075, 8840, 391, 19333, 243, 367, 3534, 1492, 22743, 183, 16, 17, 2222, 575, 12517, 243, 969, 1836, 398, 16, 1987, 17, 444, 2040, 10704, 367, 4762, 24859, 240, 10563, 398, 18, 16885, 19765, 16, 620, 22094, 8831, 22764, 6396, 16, 23, 9117, 27777, 16585, 18, 3179, 5845, 3, 2, 7510, 243, 4413, 235, 3512, 2596, 16, 6011, 1639, 246, 1776, 712, 17, 14202, 1051, 3, 2, 12284, 27751, 1214, 30, 183, 13553, 16, 6428, 1852, 184, 187, 3327, 508, 290, 230, 18, 767, 17695, 11795, 12284, 27751, 1214, 2182, 1514, 15364, 11770, 30, 183, 659, 3449, 16, 6158, 7529, 183, 5738, 22, 184, 367, 1523, 22333, 1813, 500, 29938, 245, 9934, 243, 2182, 18, 23392, 9990, 250, 9344, 639, 250, 16, 400, 14319, 23115, 367, 24101, 241, 236, 16, 11020, 18044, 2343, 2361, 6855, 18, 15185, 16, 6661, 1666, 8674, 250, 5055, 15075, 838, 2492, 932, 3785, 613, 3449, 10668, 367, 1183, 4000, 381, 18, 9226, 16, 6180, 23697, 250, 7033, 1315, 10042, 830, 6180, 27075, 369, 9450, 1056, 16, 707, 28126, 478, 527, 1850, 2363, 613, 28928, 18, 13187, 239, 14889, 418, 24361, 1435, 1099, 11031, 183, 6661, 4087, 2229, 184, 891, 11872, 689, 364, 22915, 24394, 1910, 265, 22869, 250, 367, 893, 4706, 562, 18470, 19349, 392, 571, 23392, 1857, 1730, 18, 18082, 2916, 382, 28259, 367, 773, 1857, 446, 367, 3019, 1313, 711, 25617, 2909, 14508, 16, 612, 10306, 241, 10394, 897, 4373, 1397, 389, 11318, 4712, 16, 4506, 12022, 183, 6661, 4087, 547, 184, 15075, 394, 188, 367, 1679, 16, 500, 9540, 3942, 7272, 501, 483, 16631, 29543, 13981, 4723, 16225, 14552, 27083, 27327, 367, 3314, 1107, 260, 400, 389, 1910, 14007, 29673, 19479, 541, 976, 12354, 5156, 633, 18, 894, 770, 523, 595, 15414, 3267, 22538, 250, 367, 411, 22785, 396, 1439, 16, 400, 666, 662, 380, 6514, 250, 1549, 10870, 16879, 11128, 2123, 7494, 20420, 16, 579, 7567, 2949, 2511, 1440, 367, 638, 29454, 8183, 4281, 2483, 392, 6904, 27564, 1588, 18, 650, 4802, 16, 21991, 243, 188, 21991, 243, 367, 23392, 17112, 515, 18, 13553, 16, 6428, 1852, 188, 184, 19899, 29321, 1214, 2663, 16690, 543, 188, 4241, 16, 620, 8808, 11064, 1163, 27823, 378, 1098, 20375, 829, 8808, 11064, 1163, 855, 666, 24041, 188, 13334, 467, 610, 183, 578, 1132, 4383, 184, 5533, 13817, 27837, 35, 6472, 14848, 2363, 250, 1571, 30, 183, 10130, 6492, 5, 184, 3, 2, 11117, 36, 3603, 11341, 22588, 1137, 17, 1451, 19, 2253, 5087, 27041, 1451, 87, 2253, 5087, 27041, 11117, 3560, 3761, 271, 3761, 271, 635, 2012, 3560, 18, 4353, 47, 17, 17, 17, 18, 4353, 3761, 572, 18, 635, 389, 2012, 3560, 18, 4353, 56, 17, 47, 17, 17, 17, 18, 4353, 4695, 3761, 572, 18, 7231, 16991, 17, 51, 2942, 271, 13320, 18, 6003, 62, 17, 17]}, {'input_ids': [17, 17, 18, 6003, 2942, 572, 18, 389, 13320, 18, 6003, 56, 17, 62, 17, 17, 17, 17, 18, 6003, 4695, 2942, 572, 18, 3827, 25401, 18, 18362, 17, 17, 62, 17, 17, 17, 17, 56, 20021, 271, 8931, 29834, 595, 827, 990, 18, 5870, 50, 17, 17, 17, 17, 62, 17, 17, 17, 17, 17, 18, 5870, 20021, 572, 8931, 29834, 18, 595, 389, 827, 990, 18, 5870, 56, 17, 50, 17, 17, 17, 17, 62, 17, 17, 17, 17, 17, 18, 5870, 4695, 20021, 572, 8931, 29834, 18, 2291, 2947, 439, 1816, 17, 51, 1816, 18614, 444, 23599, 243, 18, 3716, 47, 17, 17, 17, 17, 18, 3716, 1816, 11936, 234, 18, 444, 389, 543, 23599, 18, 3716, 56, 17, 47, 17, 17, 17, 17, 18, 3716, 4695, 1816, 11936, 234, 18, 13829, 366, 1916, 17, 17, 17, 17, 51, 7305, 12510, 4223, 138, 2948, 259, 35, 15725, 64, 17, 55, 17, 17, 17, 17, 17, 17, 17, 35, 15725, 2970, 7305, 12510, 4653, 234, 35, 389, 138, 2948, 259, 35, 15725, 64, 17, 56, 17, 55, 17, 17, 17, 17, 17, 17, 17, 35, 15725, 2970, 4695, 7305, 12510, 4653, 234, 35, 779, 7355, 516, 4116, 17, 17, 51, 4116, 2058, 271, 562, 779, 3412, 259, 18, 15725, 64, 17, 61, 17, 17, 17, 17, 17, 35, 15725, 2970, 4116, 2058, 572, 35, 562, 389, 779, 3412, 259, 18, 15725, 64, 17, 56, 17, 61, 17, 17, 17, 17, 17, 35, 15725, 2970, 4695, 4116, 2058, 572, 35, 13897, 296, 1451, 15, 2253, 5087, 27041, 12, 3431, 17, 2472, 13, 3, 2, 2985, 4010, 1539, 3243, 28979, 237, 378, 801, 297, 4097, 403, 8248, 3115, 549, 2145, 6802, 18, 1253, 16, 793, 30, 2830, 2775, 30, 2985, 4010, 1539, 3243, 2985, 243, 367, 2985, 4010, 1539, 3243, 9474, 9456, 6195, 28979, 11328, 7443, 367, 4090, 801, 297, 2419, 297, 5759, 12774, 549, 18, 7906, 1539, 1474, 636, 2959, 6872, 12774, 412, 9474, 14365, 4109, 19250, 10450, 243, 367, 10960, 7237, 13631, 5984, 18, 19197, 10396, 363, 2329, 27433, 23632, 14472, 16, 15275, 19197, 10396, 240, 367, 12179, 241, 15079, 18, 6, 10558, 19, 7041, 1683, 3816, 367, 3758, 12590, 1843, 633, 2574, 16, 912, 2770, 1414, 7110, 13685, 368, 5302, 23900, 666, 9516, 855, 16, 2072, 2678, 650, 813, 3898, 6184, 15271, 4109, 28979, 474, 367, 3422, 14634, 10285, 16, 620, 28979, 1990, 7828, 2878, 11201, 6, 16, 178, 16483, 21355, 18, 3243, 19197, 819, 3459, 10471, 1029, 21847, 250, 1733, 16, 5291, 28218, 3987, 7281, 18, 17853, 1166, 30, 2985, 4010, 2679, 16, 2985, 4010, 1539, 3243, 3524, 3488, 2540, 16, 23, 5152, 2419, 1607, 9130, 464, 6106, 259, 11547, 972, 1329, 367, 5244, 3501, 12774, 243, 3488, 2540, 16, 23, 5152, 2419, 1607, 9130, 464, 6106, 259, 11547, 972, 1329, 367, 5244, 3501, 12774, 243, 3, 2, 21262, 1092, 1075, 30, 46, 2270, 17966, 1017, 9116, 4693, 1164, 1413, 16, 898, 30, 3334, 421, 26969, 3731, 8046, 522, 444, 13163, 11918, 380, 6785, 6737, 9720, 250, 367, 4673, 1532, 1440, 18, 444, 15087, 6785, 1414, 13631, 12892], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [55, 56, 57, 58, 59, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 89, 90, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 109, 110, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 134, 135, 135, 136, 137, 137, 137, 138, 139, 140, 141, 141, 142, 143, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 153, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 171, 171, 172, 173, 173, 174, 175, 176, 177, 178, 179, 180, 180, 180, 181, 181, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 197, 197, 197, 198, 199, 200, 200, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 219, 219, 219, 220, 221, 221, 221, 222, 223, 224, 225, 226, 226, 226, 227, 228, 228, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 242, 242, 243, 244, 245, 246, 246, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 263, 263, 264, 265, 265, 266, 267, 268, 268, 268, 269, 270, 271, 272, 273, None, None, 0, 1, 2, 3, 4, 4, 4, 5, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35, 36, 36, 37, 37, 38, 39, 39, 40, 41, 42, 43, 43, 44, 45, 46, 46, 47, 48, 49, 50, 51, 51, 52, 53, 54, 55, 56, 57, 58, 58, 58, 59, 60, 61, 62, 63, 64, 65, 65, 65, 66, 67, 67, 67, 68, 69, 70, 71, 72, 73, 73, 74, 75, 75, 75, 75, 76, 77, 78, 79, 80, 81, 82, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 97, 98, 99, 100, 101, 102, 103, 104, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 115, 116, 117, 117, 118, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 145, 146, 146, 147, 148, 149, 150, 151, 152, 153, 153, 154, 155, 156, 157, 158, 159, 160, 161, 161, 162, 162, 163, 164, 165, 166, 167, 168, 169, 169, None, None, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 19, 19, 19, 20, 21, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], 'labels': [17, 17, 18, 6003, 2942, 572, 18, 389, 13320, 18, 6003, 56, 17, 62, 17, 17, 17, 17, 18, 6003, 4695, 2942, 572, 18, 3827, 25401, 18, 18362, 17, 17, 62, 17, 17, 17, 17, 56, 20021, 271, 8931, 29834, 595, 827, 990, 18, 5870, 50, 17, 17, 17, 17, 62, 17, 17, 17, 17, 17, 18, 5870, 20021, 572, 8931, 29834, 18, 595, 389, 827, 990, 18, 5870, 56, 17, 50, 17, 17, 17, 17, 62, 17, 17, 17, 17, 17, 18, 5870, 4695, 20021, 572, 8931, 29834, 18, 2291, 2947, 439, 1816, 17, 51, 1816, 18614, 444, 23599, 243, 18, 3716, 47, 17, 17, 17, 17, 18, 3716, 1816, 11936, 234, 18, 444, 389, 543, 23599, 18, 3716, 56, 17, 47, 17, 17, 17, 17, 18, 3716, 4695, 1816, 11936, 234, 18, 13829, 366, 1916, 17, 17, 17, 17, 51, 7305, 12510, 4223, 138, 2948, 259, 35, 15725, 64, 17, 55, 17, 17, 17, 17, 17, 17, 17, 35, 15725, 2970, 7305, 12510, 4653, 234, 35, 389, 138, 2948, 259, 35, 15725, 64, 17, 56, 17, 55, 17, 17, 17, 17, 17, 17, 17, 35, 15725, 2970, 4695, 7305, 12510, 4653, 234, 35, 779, 7355, 516, 4116, 17, 17, 51, 4116, 2058, 271, 562, 779, 3412, 259, 18, 15725, 64, 17, 61, 17, 17, 17, 17, 17, 35, 15725, 2970, 4116, 2058, 572, 35, 562, 389, 779, 3412, 259, 18, 15725, 64, 17, 56, 17, 61, 17, 17, 17, 17, 17, 35, 15725, 2970, 4695, 4116, 2058, 572, 35, 13897, 296, 1451, 15, 2253, 5087, 27041, 12, 3431, 17, 2472, 13, 3, 2, 2985, 4010, 1539, 3243, 28979, 237, 378, 801, 297, 4097, 403, 8248, 3115, 549, 2145, 6802, 18, 1253, 16, 793, 30, 2830, 2775, 30, 2985, 4010, 1539, 3243, 2985, 243, 367, 2985, 4010, 1539, 3243, 9474, 9456, 6195, 28979, 11328, 7443, 367, 4090, 801, 297, 2419, 297, 5759, 12774, 549, 18, 7906, 1539, 1474, 636, 2959, 6872, 12774, 412, 9474, 14365, 4109, 19250, 10450, 243, 367, 10960, 7237, 13631, 5984, 18, 19197, 10396, 363, 2329, 27433, 23632, 14472, 16, 15275, 19197, 10396, 240, 367, 12179, 241, 15079, 18, 6, 10558, 19, 7041, 1683, 3816, 367, 3758, 12590, 1843, 633, 2574, 16, 912, 2770, 1414, 7110, 13685, 368, 5302, 23900, 666, 9516, 855, 16, 2072, 2678, 650, 813, 3898, 6184, 15271, 4109, 28979, 474, 367, 3422, 14634, 10285, 16, 620, 28979, 1990, 7828, 2878, 11201, 6, 16, 178, 16483, 21355, 18, 3243, 19197, 819, 3459, 10471, 1029, 21847, 250, 1733, 16, 5291, 28218, 3987, 7281, 18, 17853, 1166, 30, 2985, 4010, 2679, 16, 2985, 4010, 1539, 3243, 3524, 3488, 2540, 16, 23, 5152, 2419, 1607, 9130, 464, 6106, 259, 11547, 972, 1329, 367, 5244, 3501, 12774, 243, 3488, 2540, 16, 23, 5152, 2419, 1607, 9130, 464, 6106, 259, 11547, 972, 1329, 367, 5244, 3501, 12774, 243, 3, 2, 21262, 1092, 1075, 30, 46, 2270, 17966, 1017, 9116, 4693, 1164, 1413, 16, 898, 30, 3334, 421, 26969, 3731, 8046, 522, 444, 13163, 11918, 380, 6785, 6737, 9720, 250, 367, 4673, 1532, 1440, 18, 444, 15087, 6785, 1414, 13631, 12892]}]\n",
      "\n",
      "'>>> [CLS] [MASK] ისმაილოვა [MASK] მე მათ დღის [MASK] [MASK] გამოვიყვან მედია ხადიჯა ისმაილოვა : მე [MASK] დღის სინათლეზე გამოვიყვან [MASK] 03, [MASK] [MASK] [MASK] გამომძიებელი [MASK] [MASK] [MASK] [MASK], რომ მას, სამშობლოში დაბრუნების შემთხვევაში, დაპატიმრება ემუქრება. [MASK] [MASK] ამ განცხადების ფონია [MASK] [MASK] [MASK] [MASK] აზერბაიჯანში დამოუკიდებელი ჟურნალისტებისა [MASK] უფლებადამცველი აქტივისტების დევნა [MASK] რასაც [MASK] [MASK] მხრიდან არაერთი სპროტესტო განცხადება მოჰყვა. ხადიჯა ისმაილოვა, [MASK] [MASK] თავისუფლების აზერბაიჯანულ [MASK] დილის პროგრამას [MASK] [MASK] [MASK] პრეზიდენტ ილხამ ალიევისა და მისი ოჯახის წევრების ბიზნესინტერესების შესახებ გამოქვეყნებული [MASK] მწვავე პუბლიკაციით არის ცნობილი. როგორც ხადიჯა ამბობს [MASK] მის წინააღმდეგ [MASK] მუხლით აღძრულია სისხლის სამართლის საქმე და 3 ოქტომბერს სასამართლოშია გამოძახებული : „ გაფრთხილებული ვარ, [MASK] მივლინებიდან [MASK] შემდეგ [MASK] [MASK] [MASK], რაც დაშინების [MASK] მეთოდია [MASK] დარწმუნებული ვარ, [MASK] [MASK] [MASK] არ დავბრუნდე [MASK], ანდა შევშინდე და აღარ ვილაპარაკო ხმამაღლა [MASK], რაც აზერბაიჯანში ხდება. მათ უნდა შეიგნონ, რომ ამ [MASK] ჩემთან ვერაფერს [MASK] “. ხადიჯა [MASK] მის წინააღმდეგ [MASK] [MASK] გამოძიებას აზერბაიჯანში [MASK] [MASK] [MASK] აქტივისტების იმ დევნის შემადგენელ [MASK] მიიჩნევს, რაც [MASK] გაძლიერდა [MASK] მას შემდეგ [MASK] რაც მაისში აზერბაიჯანი ევროსაბჭოს [MASK] საბჭოს მორიგე თავმჯდომარე [MASK]. ადგილობრივი უფლებადამცველი [MASK] [MASK], [MASK] დაახლოებით 87 პოლიტიკური პატიმარია, მათ შორის 14 დამოუკიდებელი ჟურნალისტი და ბლოგერია. ხადიჯა [MASK] [MASK] წანააღმდეგ სისხლის [MASK] [MASK] [MASK] ცილისწამების მუხლით. იგი ეფუძნება ისმაილოვას მიერ სოციალურ ქსელში [MASK] ინფორმაციას იმის თაობაზე, რომ აზერბაიჯანის სპეცსამსახურები ფარული გზით მოპოვებულ მაკომპრომეტირებელ მასალებს [MASK] შანტაჟისათვის, [MASK] ერთმა ოპოზიციონერმა აქტივისტმა იჯაშუშოს [MASK] [MASK] მიაწოდოს ინფორმაცია [MASK] ისმაილოვა აცხადებს, რომ [MASK], ერთ - ერთი [MASK] დაშანტაჟებული პირის თხოვნით, [MASK] ვინაობა არ ახსენა, მაგრამ მან [MASK] უჩივლა ცილისწამების გამო. ხადიჯა ამბობს, რომ მისი განზრახვა არის ამხილოს [MASK] მეთოდი, რომლითაც ხელისუფლება მოქმედებს : „ აზერბაიჯანის [MASK] უშიშროების სამინისტრო და აზერბაიჯანის სპეცსამსახურები [MASK] არიან იმით, რომ საიდუმლოდ იწერენ მათ [MASK] კრიტიკულად [MASK] ადამიანების სექსუალურ [MASK]. ასეთი ჩანაწერები ჩემ წინააღმდეგაც გამოიყენეს, გამოიყენეს სხვების წინააღმდეგაც. ჩემთვის ეს [MASK] იქნება [MASK], რომ მზის სინათლეზე გამოვიტანო აზერბაიჯანში დამკვირდებული [MASK] პრაქტიკა “. გასულ წელს [MASK] - [MASK] ვებსაიტმა [MASK] რომელიც [MASK] მმართველ „ იენი აზერბაიჯანის პარტიასთან “ არის კავშირში, გამოაქვეყნა წერილი, სათაურით „ ხადიჯას სომეხი დედა უნდა მოკვდეს “. სტატიაში [MASK] [MASK] [MASK] მდებარე [MASK] დასახლების მისამართი, სადაც ხადიჯას დედა [MASK]. პუბლიკაციაში ასევე იყო ცნობა ხადიჯას დის შესახებ, რომელიც [MASK] [MASK] თურქეთში „ სექსუალური ტრეფიკინგით “ არის დაკავებული. 2012 [MASK] კი ინტერნეტში გავრცელდა'\n",
      "\n",
      "'>>> ხადიჯა ისმაილოვას პირადი [MASK] ამსახველი უკანონო ჩანაწერები [MASK] თუმცა გამომძიებელი ჟურნალისტი [MASK] აპირებს ფარ - ხმლის დაყრას და [MASK], [MASK] მოვლენათა ნებისმიერი განვითარების შემთხვევაში არ აპირებს [MASK] დარჩენას. „ [MASK] [MASK] [MASK] იქნება უძლიერესი დარტყმა ხელისუფლების ზეწოლის ქვეშ მყოფ აზერბაიჯანულ მედიასა და სამოქალაქო სექტორზე “ [MASK] - ამბობს რებეკა [MASK] [MASK] [MASK], აშშ - ის ყოფილი [MASK] და ამჟამად უფლებადამცველი აქტივისტი. [MASK] [MASK], რომელიც სტრასბურგში იმყოფებოდა [MASK] [MASK], 3 ოქტომბერს ბრუნდება ბაქოში. ამავე [MASK] [SEP] [CLS] ჟანა ტარხანოვა, ვლადიკავკაზი - ცხინვალი [SEP] [CLS] პაატა ბურჭულაძე : [MASK] [MASK], ჩემო საქართველო ” • artinfo. ge ოპერის [MASK] პაატა ბურჭულაძე ქვეყანაში მიმდინარე [MASK] [MASK] : “ როგორც იქნა, გამოირთო “ რუსთავი [MASK] ” და ხომ ატყობთ რა საამო სიმშვიდეა ქვეყანაში [MASK] აღარავინ ტეხს განგაშს, რომ [MASK] [MASK] [MASK] სიღარიბე, აღარც ოკუპაციის თემა მუსირებს. აგერ, ია კერძაიას სიცოცხლის [MASK] [MASK] ბრალეული მხარე ვერ იქნა აღმოჩენილი და [MASK] დახურეს. სამაგიეროდ, [MASK] ხაზარაძეს პასუხს აგებინებენ მამუკა ხაზარაძისვე დაზარალებაში [MASK] [MASK] დაზარალებული ან მომჩივანი ვერ იპოვნეს [MASK] უსახლკაროდ მიტოვებული ოჯახებისთვის ფონდ [MASK] იავნანას ” [MASK] ნაჩუქარ [MASK] [MASK] დაუწუნეს და ორი წელია მათ პურის ფულითაც კი აღარავინ დახმარებია [MASK] პროკურატურამ ეძება ფონდში და მხოლოდ დახმარებული და სარგებელმიღებული ხალხი [MASK], მაგრამ მავნებლურად საქმეს მაინც [MASK] ხურავენ [MASK] ბოლომდე უნდათ “ [MASK] [MASK] [MASK] ” მოსპონ … და [MASK], რა [MASK] იქნებოდა ივანიშვილისთვის ასწლოვანი ხეების შრიალში დღეების გატარება ინგა გრიგოლია და [MASK] პირველიც რომ [MASK] დაურღვევდნენ მყუდროებას ახალი სატელევიზიო სეზონიდან. ისე ძალიან უნდა მას აგვისტოში გააჩუმოს და მოათავოს ყველაფერი, რომ მისი მონები ბატონის სურვილების [MASK] ყველაფერზე [MASK] აწერენ, [MASK] საქციელზე მზად არიან და შემდეგ [MASK] [MASK] [MASK] [MASK] [MASK] მარტივად [MASK] [MASK]. რაც მთავარია, სიჩუმეა … სიჩუმეა და [MASK] [MASK] [MASK] [MASK] ვაი, ჩემო საქართველო … ” [MASK] დუმბაძე სრულიად სამართლიანად არის [MASK] ამბავი, რომელიც [MASK] [MASK] [MASK] სამართლიანობაში დაგარწმუნებთ [MASK] რჩეულიშვილის [MASK] მისი შემოქმედების … გადავა [MASK] არა “ კომედი ჯგუფი ” ნიკა [MASK] არხზე [MASK] მარიამ ხაჭვანის განცხადება [MASK] “ [MASK] სიმართლე [MASK] ” [SEP] [CLS] [MASK] @ [MASK] [MASK] [MASK] [MASK] - ქართული / esperanto ქართული » esperanto გრძნობები სურვილი [MASK] [MASK] [MASK] [MASK] [MASK] გვაქვს სურვილი. [MASK] e - - [MASK] [MASK] ni emas. ჩვენ არ გვაქვს სურვილი. [MASK] n - [MASK] - - [MASK]. ni [MASK] emas. [MASK] ti - i timi მეშინია [MASK] mi [MASK] - -'\n",
      "\n",
      "'>>> - [MASK]. mi timas [MASK] არ მეშინია. [MASK] n - t - [MASK] - [MASK] [MASK] mi [MASK] timas [MASK] დროის ქონა. ha - [MASK] t - - - [MASK] [MASK] havi tempon მას აქვს დრო. li h [MASK] - [MASK] - [MASK] - - - - -. li havas tempon. მას არ აქვს დრო. li n - h - - - - t [MASK] - - - -. [MASK] [MASK] havas tempon. მოწყენილობა en - [MASK] enui ის [MASK] [MASK]. si [MASK] [MASK] - - -. si [MASK] [MASK] [MASK]. ის [MASK] არის მოწყენილი [MASK] si n - e [MASK] [MASK] - - [MASK] si [MASK] [MASK] [MASK] [MASK]. შიმშილი ma - - - - [MASK] [MASK] [MASK] [MASK] გშიათ? cu v [MASK] m - - - - - - -? cu vi malsatas? არ გშიათ? [MASK] [MASK] - n - [MASK] [MASK] - - - - [MASK] - [MASK] cu vi [MASK] malsatas? წყურვილი so - - i soifi მათ [MASK] [MASK] [MASK]. [MASK] v [MASK] [MASK] - - - - [MASK]? cu vi [MASK] [MASK] [MASK]? მათ არ [MASK] [MASK] [MASK] [MASK] cu v - n - s - - - - [MASK]? cu vi ne soifas [MASK] [MASK] [MASK] ქართული + esperanto ( 51 - [MASK] ) [SEP] [CLS] სოფლის მეურნეობის განვითარების [MASK] რებრენდინგში [MASK] [MASK] ათასზე მეტს ხარჯავს 31 jan. 2020, [MASK] : 37 [MASK] : სოფლის მეურნეობის განვითარების სააგენტო სოფლისა და სოფლის მეურნეობის განვითარების სააგენტო უწყების ხელმძღვანელის გადაწყვეტილებით [MASK] [MASK] იწყებს და მასში 156 326 ლარს [MASK] [MASK]. გაეროს განვითარების პროგრამიდან მიღებული თანხის [MASK] [MASK] უწყების ხელმძღვანელმა სააგენტოს ფუნქციების [MASK] [MASK] და სახელის შეცვლის [MASK] [MASK]. ბრენდინგის ფარგლებში დაგეგმილია ბრენდის სტრატეგიის, ვიზუალური ბრენდინგი და ბრენდბუქი. \" პროგრამების [MASK] პროექტების რაოდენობიდან და [MASK] [MASK] [MASK] [MASK] [MASK], ასევე მნიშვნელოვანია სხვადასხვა სამიზნე აუდიტორიამ [MASK] გაიგოს მისი დანიშნულების შესახებ, შესაბამისად საჭიროა რაც [MASK] მოკლე დროში განხორციელდეს სააგენტოს რებრენდინგი და შესაბამისი [MASK] კამპანია [MASK] რომელიც [MASK] [MASK] განხორციელების შემდგომ განისაზღვრება \" [MASK] [MASK] [MASK] სააგენტოში. სააგენტო ბრენდირების მომსახურების შესყიდვას ტენდერის გარეშე [MASK] პირდაპირი შესყიდვის გზით აპირებს. გაიგეთ მეტი [MASK] სოფლის მეურნეობის [MASK] [MASK] სოფლის [MASK] განვითარების სააგენტო პოლიტიკა პრეზიდენტის თქმით, [MASK] თვეში 32 ქვეყნის [MASK] [MASK] მობილურით საუბარში 200 ლარი [MASK] 98 თეთრი [MASK] [MASK] პრეზიდენტის თქმით [MASK] 3 თვეში 32 [MASK] [MASK] [MASK] მობილურით საუბარში 200 ლარი და 98 თეთრი დახარჯა [SEP] [CLS] წასულებისა იყოს : d by bennu on tue jul [MASK] 2015, 14 [MASK] 53 ამ თემაში მოვიხსენიოთ [MASK] იუზერები რომლებმაც დაგვტოვეს და [MASK] აღარ არიან. ის ადამიანებმა [MASK] [MASK] მიზეზით წავიდნენ'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(3)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:02:20.248985Z",
     "end_time": "2023-06-03T15:02:20.282988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mask_token'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataCollatorForWholeWordMask\n\u001B[0;32m      3\u001B[0m samples \u001B[38;5;241m=\u001B[39m [lm_datasets[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m][i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m)]\n\u001B[1;32m----> 4\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[43mDataCollatorForWholeWordMask\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m>>> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtokenizer\u001B[38;5;241m.\u001B[39mdecode(chunk)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m<string>:9\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, tokenizer, mlm, mlm_probability, pad_to_multiple_of, tf_experimental_compile, return_tensors)\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\transformers\\data\\data_collator.py:642\u001B[0m, in \u001B[0;36mDataCollatorForLanguageModeling.__post_init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    641\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__post_init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 642\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlm \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmask_token\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    643\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    644\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis tokenizer does not have a mask token which is necessary for masked language modeling. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    645\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou should pass `mlm=False` to train on causal language modeling instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    646\u001B[0m         )\n\u001B[0;32m    647\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtf_experimental_compile:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'mask_token'"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForWholeWordMask\n",
    "\n",
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = DataCollatorForWholeWordMask(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 1000\n    })\n})"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 10_000\n",
    "test_size = int(0.1 * train_size)\n",
    "\n",
    "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T13:45:38.258789Z",
     "end_time": "2023-05-29T13:45:38.384278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n    num_rows: 2509639\n})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets[\"train\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:41:30.197471Z",
     "end_time": "2023-06-03T15:41:30.203471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    lm_datasets[\"train\"],\n",
    "    collate_fn=wholde_word_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "eval_dataset = concatenate_datasets([lm_datasets[\"test\"], lm_datasets[\"validation\"]])\n",
    "tf_eval_dataset = model.prepare_tf_dataset(\n",
    "    eval_dataset,\n",
    "    collate_fn=wholde_word_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:47:19.075076Z",
     "end_time": "2023-06-03T15:47:19.210400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:44:05.575412Z",
     "end_time": "2023-06-03T15:44:05.577412Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "C:\\Users\\Davit6174\\PycharmProjects\\pythonProject\\distilbert-base-uncased-finetuned-mc4-cleaned-52000 is already a clone of https://huggingface.co/Davit6174/distilbert-base-uncased-finetuned-mc4-cleaned-52000. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_steps = len(tf_train_dataset)\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "callback = PushToHubCallback(\n",
    "    output_dir=f\"{model_name}-finetuned-mc4-cleaned-52000\", tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:47:21.445954Z",
     "end_time": "2023-06-03T15:47:22.715422Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25/4916 [..............................] - ETA: 38:31 - loss: 14.0956"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m eval_loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf_eval_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPerplexity: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmath\u001B[38;5;241m.\u001B[39mexp(eval_loss)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\keras\\engine\\training.py:1947\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1944\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1945\u001B[0m ):\n\u001B[0;32m   1946\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 1947\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1949\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    955\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    956\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    957\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_loss = model.evaluate(tf_eval_dataset)\n",
    "print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T13:46:17.868649Z",
     "end_time": "2023-05-29T14:02:07.691141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78426/78426 [==============================] - 29664s 378ms/step - loss: 4.5141 - val_loss: 3.9369\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x26ecea27eb0>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, validation_data=tf_eval_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T15:47:27.222756Z",
     "end_time": "2023-06-04T00:01:51.745808Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model.save_pretrained('distilbert-base-uncased-fine-tuned-cleaned')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T00:03:45.072047Z",
     "end_time": "2023-06-04T00:03:45.529202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=model, tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T00:04:39.088150Z",
     "end_time": "2023-06-04T00:04:39.103100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> გამარჯობა, მე დავითი ვარ 0.279\n",
      ">>> გამარჯობა, მე დავითი : 0.108\n",
      ">>> გამარჯობა, მე დავითი - 0.088\n",
      ">>> გამარჯობა, მე დავითი, 0.065\n",
      ">>> გამარჯობა, მე დავითი. 0.059\n"
     ]
    }
   ],
   "source": [
    "# text = 'ძალიან [MASK] საჭმელია, სულ მინდება'\n",
    "text = 'გამარჯობა, მე დავითი [MASK]'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\", round(pred['score'], 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T00:19:53.439719Z",
     "end_time": "2023-06-04T00:19:53.641386Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
