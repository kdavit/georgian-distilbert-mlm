{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-18T18:16:15.939328Z",
     "end_time": "2023-06-18T18:16:25.108122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForMaskedLM.\n",
      "\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased-fine-tuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForMaskedLM.\n",
      "\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased-fine-tuned-cleaned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForMaskedLM.\n",
      "\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at larger-data-model/distilbert-base-uncased-fine-tuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForMaskedLM, DistilBertTokenizerFast\n",
    "\n",
    "model_base = TFAutoModelForMaskedLM.from_pretrained('distilbert-base-uncased-fine-tuned')\n",
    "tokenizer_base = DistilBertTokenizerFast.from_pretrained('tokenizer')\n",
    "\n",
    "model_pre = TFAutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased-fine-tuned-cleaned\")\n",
    "tokenizer_pre = DistilBertTokenizerFast.from_pretrained('test-tokenizer-cleaned-30000')\n",
    "\n",
    "\n",
    "model_large = TFAutoModelForMaskedLM.from_pretrained('larger-data-model/distilbert-base-uncased-fine-tuned')\n",
    "tokenizer_large = DistilBertTokenizerFast.from_pretrained('larger-data-model/distilbert-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler_base = pipeline(\n",
    "    \"fill-mask\", model=model_base, tokenizer=tokenizer_base\n",
    ")\n",
    "\n",
    "mask_filler_pre = pipeline(\n",
    "    \"fill-mask\", model=model_pre, tokenizer=tokenizer_pre\n",
    ")\n",
    "\n",
    "mask_filler_large = pipeline(\n",
    "    \"fill-mask\", model=model_large, tokenizer=tokenizer_large\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-18T18:16:25.108122Z",
     "end_time": "2023-06-18T18:16:25.169897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** model_base *****\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომო გაიტანა 0.099\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომი გაიტანა 0.073\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომა გაიტანა 0.068\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომთ გაიტანა 0.064\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომანის გაიტანა 0.035\n",
      "\n",
      "\n",
      "***** model_pre *****\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ გოლი გაიტანა 0.092\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ ვერ გაიტანა 0.055\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ გაიტანა გაიტანა 0.05\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ ბურთი გაიტანა 0.047\n",
      ">>> სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ არ გაიტანა 0.029\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'ძალიან [MASK] საჭმელია'\n",
    "# 'ეს პიცა ძალიან [MASK]'\n",
    "# 'ქართული ენა საკმაოდ [MASK]'\n",
    "# 'საქართველოს ეროვნული [MASK]'\n",
    "# 'ბევრი რამ ჯერ კიდევ [MASK] ვიცი'\n",
    "# 'ჯანსაღი ცხოვრება [MASK] მოსდევს'\n",
    "# 'ქართული [MASK] სწავლა საკმაოდ რთულია'\n",
    "# 'გამარჯობა, მე დავითი [MASK]'\n",
    "# text = 'სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ [MASK] გაიტანა'\n",
    "# 'სამაგისტრო ნაშრომისთვის ბევრი [MASK] ფაქტი მჭირდება'\n",
    "\n",
    "text = 'სტადიონი ინგრეოდა ფანების ძახილით როდესაც რონალდომ [MASK] გაიტანა'\n",
    "\n",
    "\n",
    "preds = [mask_filler_base(text), mask_filler_pre(text)]\n",
    "model_names = ['model_base', 'model_pre']\n",
    "\n",
    "for model, name in zip(preds, model_names):\n",
    "    print('***** ' + name + ' *****')\n",
    "    for pred in model:\n",
    "        print(f\">>> {pred['sequence']}\", round(pred['score'], 3))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-18T21:40:20.597961Z",
     "end_time": "2023-06-18T21:40:20.900448Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, DataCollatorForWholeWordMask\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer_pre, mlm_probability=0.15)\n",
    "wholde_word_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer_pre, mlm_probability=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-05T02:30:38.691828Z",
     "end_time": "2023-06-05T02:30:38.704828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davit6174\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\transformers\\data\\data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "lm_datasets = load_from_disk(\"distilbert-model/lm_dataset-30000\")\n",
    "tf_train_dataset = model_base.prepare_tf_dataset(\n",
    "    lm_datasets[\"train\"],\n",
    "    collate_fn=wholde_word_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "eval_dataset = concatenate_datasets([lm_datasets[\"test\"], lm_datasets[\"validation\"]])\n",
    "tf_eval_dataset = model_base.prepare_tf_dataset(\n",
    "    eval_dataset,\n",
    "    collate_fn=wholde_word_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-05T02:30:49.916774Z",
     "end_time": "2023-06-05T02:30:51.529487Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4090, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_steps = len(tf_train_dataset)\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model_pre.compile(optimizer=optimizer)\n",
    "model_base.compile(optimizer=optimizer)\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-05T02:30:56.699280Z",
     "end_time": "2023-06-05T02:30:56.732299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_loss = model_pre.evaluate(tf_eval_dataset)\n",
    "print(f\"Perplexity of model_pre: {math.exp(eval_loss):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-05T00:53:30.826559Z",
     "end_time": "2023-06-05T00:53:30.840571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19662/19662 [==============================] - 2385s 121ms/step - loss: 8.4390\n",
      "Perplexity of model_base: 4623.76\n"
     ]
    }
   ],
   "source": [
    "eval_loss = model_base.evaluate(tf_eval_dataset)\n",
    "print(f\"Perplexity of model_base: {math.exp(eval_loss):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-05T00:53:38.630272Z",
     "end_time": "2023-06-05T01:33:23.159062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "eval_loss_pre = model_pre.evaluate(tf_eval_dataset)\n",
    "print(f\"Perplexity of model_pre: {math.exp(eval_loss):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T06:58:33.855065Z",
     "end_time": "2023-06-04T07:36:14.741800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "f = open(\"perplexity.txt\", \"w\")\n",
    "f.write(f\"Perplexity of model_base: {math.exp(eval_loss):.2f}\" + \"\\n\" + f\"Perplexity of model_pre: {math.exp(eval_loss_pre):.2f}\")\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-04T08:41:56.957191Z",
     "end_time": "2023-06-04T08:41:56.975214Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
